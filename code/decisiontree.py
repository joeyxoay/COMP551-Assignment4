# -*- coding: utf-8 -*-
"""DecisionTree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17BZki8wZwbNMjvAyekb5b1T0_28K4VOz
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.impute import SimpleImputer

# Decision tree model

decision_tree_model = DecisionTreeClassifier()

# Iris dataset

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']
iris = pd.read_csv(url, names=columns)

# Preprocess
X = iris.drop('Species', axis=1)
y = iris['Species']

# Encode
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# Train Decision Tree
decision_tree_model.fit(X_train, y_train)

# Predict
y_pred = decision_tree_model.predict(X_test)

# Evaluate
accuracy = accuracy_score(y_test, y_pred)
print(f"Decision Tree Accuracy: {accuracy * 100:.2f}%")

# Haberman’s Survival dataset

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data"
column_names = ["age", "year_of_treatment", "positive_lymph_nodes", "survival_status_after_5_years"]
haberman = pd.read_csv(url, names=column_names)

# Preprocess
X = haberman.drop('survival_status_after_5_years', axis=1)
y = haberman['survival_status_after_5_years']

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Decision Tree
decision_tree_model.fit(X_train, y_train)

# Predict
y_pred = decision_tree_model.predict(X_test)

# Evaluate
accuracy = accuracy_score(y_test, y_pred)
print(f"Decision Tree Accuracy: {accuracy * 100:.2f}%")

# Car Evaluation dataset

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data"
column_names = ["buying_price", "maintenance_cost", "number_of_doors", "number_of_persons", "lug_boot", "safety", "decision"]
car = pd.read_csv(url, names=column_names)

# Preprocess
X = car.drop('decision', axis=1)
y = car['decision']

# Encode categorical features
label_encoder = LabelEncoder()
X_encoded = X.apply(label_encoder.fit_transform)

# Split
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Train Decision Tree
decision_tree_model.fit(X_train, y_train)

# Predict
y_pred = decision_tree_model.predict(X_test)

# Evaluate
accuracy = accuracy_score(y_test, y_pred)
print(f"Decision Tree Accuracy: {accuracy * 100:.2f}%")

# Breast Cancer Wisconsin dataset

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data"
column_names = ["Sample_code_number", "Clump_thickness", "Uniformity_of_cell_size", "Uniformity_of_cell_shape",
                "Marginal_adhesion", "Single_epithelial_cell_size", "Bare_nuclei", "Bland_chromatin",
                "Normal_nucleoli", "Mitoses", "Class"]
cancer = pd.read_csv(url, names=column_names)

# Preprocess
X = cancer.drop('Class', axis=1)
y = cancer['Class']

# Handle missing values
X.replace('?', pd.NA, inplace=True)
X = X.apply(pd.to_numeric, errors='coerce')

# Impute missing values
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# Encode categorical features
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Split
X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_encoded, test_size=0.2, random_state=42)

# Train Decision Tree
decision_tree_model.fit(X_train, y_train)

# Predict
y_pred = decision_tree_model.predict(X_test)

# Evaluate
accuracy = accuracy_score(y_test, y_pred)
print(f"Decision Tree Accuracy: {accuracy * 100:.2f}%")

# Poker Hands dataset
url_train = "https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-training-true.data"
url_test = "https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-testing.data"
column_names = ["S1", "C1", "S2", "C2", "S3", "C3", "S4", "C4", "S5", "C5", "Class"]

# Read training and testing data
poker_train = pd.read_csv(url_train, names=column_names)
poker_test = pd.read_csv(url_test, names=column_names)

# Concatenate training and testing data for simplicity
poker = pd.concat([poker_train, poker_test], ignore_index=True)

# Preprocess
X = poker.drop('Class', axis=1)
y = poker['Class']

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Decision Tree
decision_tree_model.fit(X_train, y_train)

# Predict
y_pred = decision_tree_model.predict(X_test)

# Evaluate
accuracy = accuracy_score(y_test, y_pred)
print(f"Decision Tree Accuracy: {accuracy * 100:.2f}%")

# German Credit Dataset

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data"
column_names = ["Status of existing checking account", "Duration", "Credit history", "Purpose", "Credit amount",
                "Savings account/bonds", "Present employment since", "Installment rate in percentage of disposable income",
                "Personal status and sex", "Other debtors / guarantors", "Present residence since", "Property", "Age",
                "Other installment plans", "Housing", "Number of existing credits at this bank", "Telephone",
                "Foreign worker", "Credit risk"]
credit_data = pd.read_csv(url, names=column_names, sep=' ', header=None)

# Preprocess
X = credit_data.drop('Credit risk', axis=1)
y = credit_data['Credit risk']

# Encode categorical features
label_encoder = LabelEncoder()
X_encoded = X.apply(lambda x: label_encoder.fit_transform(x) if x.dtype == 'O' else x)

# Split
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Train Decision Tree
decision_tree_model.fit(X_train, y_train)

# Predict
y_pred = decision_tree_model.predict(X_test)

# Evaluate
accuracy = accuracy_score(y_test, y_pred)
print(f"Decision Tree Accuracy: {accuracy * 100:.2f}%")

"""# **Hyperparameters Experiments**

**Test Size (experiments)**
"""

# Haberman’s Survival dataset

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data"
column_names = ["age", "year_of_treatment", "positive_lymph_nodes", "survival_status_after_5_years"]
haberman = pd.read_csv(url, names=column_names)

# Preprocess
X = haberman.drop('survival_status_after_5_years', axis=1)
y = haberman['survival_status_after_5_years']

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

# Train Decision Tree
decision_tree_model.fit(X_train, y_train)

# Predict
y_pred = decision_tree_model.predict(X_test)

# Evaluate
accuracy = accuracy_score(y_test, y_pred)
print(f"Decision Tree Accuracy: {accuracy * 100:.2f}%")

# Haberman’s Survival dataset

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data"
column_names = ["age", "year_of_treatment", "positive_lymph_nodes", "survival_status_after_5_years"]
haberman = pd.read_csv(url, names=column_names)

# Preprocess
X = haberman.drop('survival_status_after_5_years', axis=1)
y = haberman['survival_status_after_5_years']

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

# Train Decision Tree
decision_tree_model.fit(X_train, y_train)

# Predict
y_pred = decision_tree_model.predict(X_test)

# Evaluate
accuracy = accuracy_score(y_test, y_pred)
print(f"Decision Tree Accuracy: {accuracy * 100:.2f}%")

"""**Varying Random States**"""

# Haberman’s Survival dataset

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data"
column_names = ["age", "year_of_treatment", "positive_lymph_nodes", "survival_status_after_5_years"]
haberman = pd.read_csv(url, names=column_names)

# Preprocess
X = haberman.drop('survival_status_after_5_years', axis=1)
y = haberman['survival_status_after_5_years']

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)

# Train Decision Tree
decision_tree_model.fit(X_train, y_train)

# Predict
y_pred = decision_tree_model.predict(X_test)

# Evaluate
accuracy = accuracy_score(y_test, y_pred)
print(f"Decision Tree Accuracy: {accuracy * 100:.2f}%")

# Haberman’s Survival dataset

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data"
column_names = ["age", "year_of_treatment", "positive_lymph_nodes", "survival_status_after_5_years"]
haberman = pd.read_csv(url, names=column_names)

# Preprocess
X = haberman.drop('survival_status_after_5_years', axis=1)
y = haberman['survival_status_after_5_years']

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Decision Tree
decision_tree_model.fit(X_train, y_train)

# Predict
y_pred = decision_tree_model.predict(X_test)

# Evaluate
accuracy = accuracy_score(y_test, y_pred)
print(f"Decision Tree Accuracy: {accuracy * 100:.2f}%")