{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "kxgOBNyJIcR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the Iris dataset\n",
        "url_iris = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "columns_iris = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']\n",
        "iris = pd.read_csv(url_iris, names=columns_iris)\n",
        "\n",
        "# Preprocess\n",
        "X_iris = iris.drop('Species', axis=1)\n",
        "y_iris = iris['Species']\n",
        "\n",
        "# Encode categorical features\n",
        "label_encoder_iris = LabelEncoder()\n",
        "X_encoded_iris = X_iris.apply(lambda x: label_encoder_iris.fit_transform(x) if x.dtype == 'O' else x)\n",
        "\n",
        "# One-hot encode the target variable\n",
        "y_encoded_iris = to_categorical(label_encoder_iris.fit_transform(y_iris))\n",
        "\n",
        "# Split\n",
        "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(X_encoded_iris, y_encoded_iris, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler_iris = StandardScaler()\n",
        "X_train_scaled_iris = scaler_iris.fit_transform(X_train_iris)\n",
        "X_test_scaled_iris = scaler_iris.transform(X_test_iris)\n",
        "\n",
        "# Train Neural Network\n",
        "model_iris = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled_iris.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(3, activation='softmax')  # 3 output neurons for multi-class classification (Iris dataset has 3 classes)\n",
        "])\n",
        "\n",
        "model_iris.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_iris.fit(X_train_scaled_iris, y_train_iris, epochs=20, batch_size=10, verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "loss_iris, accuracy_iris = model_iris.evaluate(X_test_scaled_iris, y_test_iris)\n",
        "print(f\"Neural Network Accuracy on Iris dataset: {accuracy_iris * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPNMoI_mJl5Z",
        "outputId": "6e919b7e-dab9-41aa-9f01-1661e284e5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "12/12 [==============================] - 1s 2ms/step - loss: 1.0113 - accuracy: 0.6167\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7999 - accuracy: 0.7333\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.8167\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.8250\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.8250\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8167\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8333\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8417\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8583\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8583\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8833\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.8833\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2426 - accuracy: 0.9417\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9500\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9500\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1990 - accuracy: 0.9500\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9500\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1726 - accuracy: 0.9583\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9500\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.1068 - accuracy: 1.0000\n",
            "Neural Network Accuracy on Iris dataset: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Habermanâ€™s Survival dataset\n",
        "\n",
        "url_haberman = \"https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data\"\n",
        "column_names_haberman = [\"age\", \"year_of_treatment\", \"positive_lymph_nodes\", \"survival_status_after_5_years\"]\n",
        "haberman = pd.read_csv(url_haberman, names=column_names_haberman)\n",
        "\n",
        "# Preprocess\n",
        "X_haberman = haberman.drop('survival_status_after_5_years', axis=1)\n",
        "y_haberman = haberman['survival_status_after_5_years']\n",
        "\n",
        "# Split\n",
        "X_train_haberman, X_test_haberman, y_train_haberman, y_test_haberman = train_test_split(X_haberman, y_haberman, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler_haberman = StandardScaler()\n",
        "X_train_scaled_haberman = scaler_haberman.fit_transform(X_train_haberman)\n",
        "X_test_scaled_haberman = scaler_haberman.transform(X_test_haberman)\n",
        "\n",
        "# Train Neural Network\n",
        "model_haberman = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled_haberman.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # 1 output neuron for binary classification\n",
        "])\n",
        "\n",
        "model_haberman.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_haberman.fit(X_train_scaled_haberman, y_train_haberman, epochs=20, batch_size=10, verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "loss_haberman, accuracy_haberman = model_haberman.evaluate(X_test_scaled_haberman, y_test_haberman)\n",
        "print(f\"Neural Network Accuracy on Haberman's Survival dataset: {accuracy_haberman * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS74P1plJ68S",
        "outputId": "5dfe4dbc-020d-418a-b735-edcfa7dadb45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "25/25 [==============================] - 2s 5ms/step - loss: 0.3979 - accuracy: 0.6803\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 0s 4ms/step - loss: -0.2201 - accuracy: 0.7418\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 0s 4ms/step - loss: -0.8078 - accuracy: 0.7418\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 0s 7ms/step - loss: -1.4834 - accuracy: 0.7418\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 0s 6ms/step - loss: -2.4327 - accuracy: 0.7418\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 0s 6ms/step - loss: -3.8563 - accuracy: 0.7418\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - 0s 9ms/step - loss: -5.7904 - accuracy: 0.7418\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - 0s 4ms/step - loss: -8.8275 - accuracy: 0.7418\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - 0s 4ms/step - loss: -12.9224 - accuracy: 0.7418\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - 0s 6ms/step - loss: -18.3772 - accuracy: 0.7418\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - 0s 7ms/step - loss: -25.3372 - accuracy: 0.7418\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - 0s 7ms/step - loss: -34.5214 - accuracy: 0.7418\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: -45.7730 - accuracy: 0.7418\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - 0s 5ms/step - loss: -58.1081 - accuracy: 0.7418\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - 0s 6ms/step - loss: -74.2122 - accuracy: 0.7418\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - 0s 4ms/step - loss: -92.0986 - accuracy: 0.7418\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - 0s 5ms/step - loss: -113.5725 - accuracy: 0.7418\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - 0s 5ms/step - loss: -139.0415 - accuracy: 0.7418\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - 0s 3ms/step - loss: -166.3431 - accuracy: 0.7418\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - 0s 4ms/step - loss: -198.4722 - accuracy: 0.7418\n",
            "2/2 [==============================] - 0s 11ms/step - loss: -208.0907 - accuracy: 0.7097\n",
            "Neural Network Accuracy on Haberman's Survival dataset: 70.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Car Evaluation dataset\n",
        "\n",
        "url_car = \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\"\n",
        "column_names_car = [\"buying_price\", \"maintenance_cost\", \"number_of_doors\", \"number_of_persons\", \"lug_boot\", \"safety\", \"decision\"]\n",
        "car = pd.read_csv(url_car, names=column_names_car)\n",
        "\n",
        "# Preprocess\n",
        "X_car = car.drop('decision', axis=1)\n",
        "y_car = car['decision']\n",
        "\n",
        "# Encode categorical features\n",
        "label_encoder_car = LabelEncoder()\n",
        "X_encoded_car = X_car.apply(lambda x: label_encoder_car.fit_transform(x) if x.dtype == 'O' else x)\n",
        "\n",
        "# One-hot encode the target variable\n",
        "y_encoded_car = to_categorical(label_encoder_car.fit_transform(y_car))\n",
        "\n",
        "# Split\n",
        "X_train_car, X_test_car, y_train_car, y_test_car = train_test_split(X_encoded_car, y_encoded_car, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler_car = StandardScaler()\n",
        "X_train_scaled_car = scaler_car.fit_transform(X_train_car)\n",
        "X_test_scaled_car = scaler_car.transform(X_test_car)\n",
        "\n",
        "# Train Neural Network\n",
        "model_car = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled_car.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(y_encoded_car.shape[1], activation='softmax')  # Output neurons based on the number of classes in 'decision'\n",
        "])\n",
        "\n",
        "model_car.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_car.fit(X_train_scaled_car, y_train_car, epochs=20, batch_size=10, verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "loss_car, accuracy_car = model_car.evaluate(X_test_scaled_car, y_test_car)\n",
        "print(f\"Neural Network Accuracy on Car Evaluation dataset: {accuracy_car * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd_QzT0_KbOc",
        "outputId": "e56bdf43-ddc7-4eb5-daf2-a759d1f3b471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "139/139 [==============================] - 1s 4ms/step - loss: 0.9445 - accuracy: 0.6368\n",
            "Epoch 2/20\n",
            "139/139 [==============================] - 1s 4ms/step - loss: 0.6399 - accuracy: 0.7185\n",
            "Epoch 3/20\n",
            "139/139 [==============================] - 1s 4ms/step - loss: 0.5216 - accuracy: 0.7699\n",
            "Epoch 4/20\n",
            "139/139 [==============================] - 1s 4ms/step - loss: 0.4144 - accuracy: 0.8307\n",
            "Epoch 5/20\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 0.3350 - accuracy: 0.8654\n",
            "Epoch 6/20\n",
            "139/139 [==============================] - 1s 4ms/step - loss: 0.2882 - accuracy: 0.8770\n",
            "Epoch 7/20\n",
            "139/139 [==============================] - 1s 4ms/step - loss: 0.2459 - accuracy: 0.9023\n",
            "Epoch 8/20\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 0.2131 - accuracy: 0.9175\n",
            "Epoch 9/20\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9436\n",
            "Epoch 10/20\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9645\n",
            "Epoch 11/20\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.1416 - accuracy: 0.9638\n",
            "Epoch 12/20\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9740\n",
            "Epoch 13/20\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9783\n",
            "Epoch 14/20\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9848\n",
            "Epoch 15/20\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.9855\n",
            "Epoch 16/20\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9841\n",
            "Epoch 17/20\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9848\n",
            "Epoch 18/20\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9863\n",
            "Epoch 19/20\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9906\n",
            "Epoch 20/20\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9877\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.9509\n",
            "Neural Network Accuracy on Car Evaluation dataset: 95.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Breast Cancer Wisconsin dataset\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\"\n",
        "column_names = [\"Sample_code_number\", \"Clump_thickness\", \"Uniformity_of_cell_size\", \"Uniformity_of_cell_shape\",\n",
        "                \"Marginal_adhesion\", \"Single_epithelial_cell_size\", \"Bare_nuclei\", \"Bland_chromatin\",\n",
        "                \"Normal_nucleoli\", \"Mitoses\", \"Class\"]\n",
        "cancer = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Function to create a simple neural network model\n",
        "def create_neural_network(input_shape):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(64, activation='relu', input_shape=input_shape),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')  # Adjust the number of units based on your classification task\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Function to preprocess data and train the neural network\n",
        "def train_neural_network(X_train, y_train, X_test, y_test):\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "    y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    input_shape = (X_train_scaled.shape[1],)  # Input shape for the neural network\n",
        "\n",
        "    model = create_neural_network(input_shape)\n",
        "    model.fit(X_train_scaled, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    y_pred_prob = model.predict(X_test_scaled)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "    print(f\"Neural Network Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Preprocess\n",
        "X = cancer.drop('Class', axis=1)\n",
        "y = cancer['Class']\n",
        "\n",
        "# Handle missing values\n",
        "X.replace('?', pd.NA, inplace=True)\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Encode categorical features\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Neural Network\n",
        "train_neural_network(X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRKcJ89eT-3L",
        "outputId": "05646913-0795-4f06-f3f5-4de6d2db4843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 1s 18ms/step - loss: 0.6152 - accuracy: 0.8031 - val_loss: 0.4610 - val_accuracy: 0.9554\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.9732 - val_loss: 0.3105 - val_accuracy: 0.9554\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2260 - accuracy: 0.9732 - val_loss: 0.2340 - val_accuracy: 0.9554\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1547 - accuracy: 0.9732 - val_loss: 0.1943 - val_accuracy: 0.9464\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1161 - accuracy: 0.9776 - val_loss: 0.1747 - val_accuracy: 0.9375\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0957 - accuracy: 0.9776 - val_loss: 0.1665 - val_accuracy: 0.9375\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9799 - val_loss: 0.1624 - val_accuracy: 0.9375\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9799 - val_loss: 0.1616 - val_accuracy: 0.9375\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9799 - val_loss: 0.1605 - val_accuracy: 0.9375\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9799 - val_loss: 0.1590 - val_accuracy: 0.9375\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "Neural Network Accuracy: 96.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Poker Hands dataset\n",
        "\n",
        "url_train = \"https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-training-true.data\"\n",
        "url_test = \"https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-testing.data\"\n",
        "column_names = [\"S1\", \"C1\", \"S2\", \"C2\", \"S3\", \"C3\", \"S4\", \"C4\", \"S5\", \"C5\", \"Class\"]\n",
        "\n",
        "# Function to create a simple neural network model\n",
        "def create_neural_network(input_shape):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(64, activation='relu', input_shape=input_shape),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')  # Adjust the number of units based on your classification task\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Function to preprocess data and train the neural network\n",
        "def train_neural_network(X_train, y_train, X_test, y_test):\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "    y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    input_shape = (X_train_scaled.shape[1],)  # Input shape for the neural network\n",
        "\n",
        "    model = create_neural_network(input_shape)\n",
        "    model.fit(X_train_scaled, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    y_pred_prob = model.predict(X_test_scaled)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "    print(f\"Neural Network Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Read training and testing data\n",
        "poker_train = pd.read_csv(url_train, names=column_names)\n",
        "poker_test = pd.read_csv(url_test, names=column_names)\n",
        "\n",
        "# Concatenate training and testing data for simplicity\n",
        "poker = pd.concat([poker_train, poker_test], ignore_index=True)\n",
        "\n",
        "# Preprocess\n",
        "X = poker.drop('Class', axis=1)\n",
        "y = poker['Class']\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Neural Network\n",
        "train_neural_network(X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-O1HgtvUpij",
        "outputId": "cc936d4e-e74a-4a8f-dae1-632a5af69eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "20501/20501 [==============================] - 66s 3ms/step - loss: -12.5340 - accuracy: 0.5394 - val_loss: -53.2202 - val_accuracy: 0.5790\n",
            "Epoch 2/10\n",
            "20501/20501 [==============================] - 65s 3ms/step - loss: -206.4970 - accuracy: 0.5620 - val_loss: -446.4886 - val_accuracy: 0.5808\n",
            "Epoch 3/10\n",
            "20501/20501 [==============================] - 62s 3ms/step - loss: -918.6462 - accuracy: 0.5430 - val_loss: -1539.4058 - val_accuracy: 0.5693\n",
            "Epoch 4/10\n",
            "20501/20501 [==============================] - 64s 3ms/step - loss: -2472.0525 - accuracy: 0.5360 - val_loss: -3624.1389 - val_accuracy: 0.5253\n",
            "Epoch 5/10\n",
            "20501/20501 [==============================] - 63s 3ms/step - loss: -5238.4004 - accuracy: 0.5287 - val_loss: -7144.4482 - val_accuracy: 0.5444\n",
            "Epoch 6/10\n",
            "20501/20501 [==============================] - 64s 3ms/step - loss: -9522.0273 - accuracy: 0.5225 - val_loss: -12336.2861 - val_accuracy: 0.4892\n",
            "Epoch 7/10\n",
            "20501/20501 [==============================] - 66s 3ms/step - loss: -15640.5059 - accuracy: 0.5225 - val_loss: -19510.6172 - val_accuracy: 0.4355\n",
            "Epoch 8/10\n",
            "20501/20501 [==============================] - 65s 3ms/step - loss: -23896.2988 - accuracy: 0.5190 - val_loss: -29017.5391 - val_accuracy: 0.4961\n",
            "Epoch 9/10\n",
            "20501/20501 [==============================] - 64s 3ms/step - loss: -34662.4062 - accuracy: 0.5170 - val_loss: -41190.2930 - val_accuracy: 0.5439\n",
            "Epoch 10/10\n",
            "20501/20501 [==============================] - 66s 3ms/step - loss: -48416.6484 - accuracy: 0.5138 - val_loss: -56693.8789 - val_accuracy: 0.5106\n",
            "6407/6407 [==============================] - 12s 2ms/step\n",
            "Neural Network Accuracy: 51.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# German Credit Dataset\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
        "column_names = [\"Status of existing checking account\", \"Duration\", \"Credit history\", \"Purpose\", \"Credit amount\",\n",
        "                \"Savings account/bonds\", \"Present employment since\", \"Installment rate in percentage of disposable income\",\n",
        "                \"Personal status and sex\", \"Other debtors / guarantors\", \"Present residence since\", \"Property\", \"Age\",\n",
        "                \"Other installment plans\", \"Housing\", \"Number of existing credits at this bank\", \"Telephone\",\n",
        "                \"Foreign worker\", \"Credit risk\"]\n",
        "credit_data = pd.read_csv(url, names=column_names, sep=' ', header=None)\n",
        "\n",
        "# Preprocess\n",
        "X = credit_data.drop('Credit risk', axis=1)\n",
        "y = credit_data['Credit risk']\n",
        "\n",
        "# Encode categorical features\n",
        "label_encoder = LabelEncoder()\n",
        "X_encoded = X.apply(lambda x: label_encoder.fit_transform(x) if x.dtype == 'O' else x)\n",
        "\n",
        "# One-hot encode the target variable\n",
        "y_encoded = to_categorical(label_encoder.fit_transform(y))\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Neural Network\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(2, activation='softmax')  # 2 output neurons for binary classification (good/bad credit)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_scaled, y_train, epochs=20, batch_size=10, verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Neural Network Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2EA450HbWew",
        "outputId": "f1020b08-015c-4f64-dc9d-4bcbdc833b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "80/80 [==============================] - 1s 2ms/step - loss: 0.6345 - accuracy: 0.6488\n",
            "Epoch 2/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7262\n",
            "Epoch 3/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7387\n",
            "Epoch 4/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7688\n",
            "Epoch 5/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7738\n",
            "Epoch 6/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7788\n",
            "Epoch 7/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7850\n",
            "Epoch 8/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7962\n",
            "Epoch 9/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8075\n",
            "Epoch 10/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8087\n",
            "Epoch 11/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8300\n",
            "Epoch 12/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8350\n",
            "Epoch 13/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8263\n",
            "Epoch 14/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8475\n",
            "Epoch 15/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8525\n",
            "Epoch 16/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8562\n",
            "Epoch 17/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8625\n",
            "Epoch 18/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8725\n",
            "Epoch 19/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.8850\n",
            "Epoch 20/20\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8788\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.7350\n",
            "Neural Network Accuracy: 73.50%\n"
          ]
        }
      ]
    }
  ]
}